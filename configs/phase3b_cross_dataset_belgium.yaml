# Phase 3B: Cross-Dataset Generalization - Belgium-Netherlands
# Test capacity-adaptive scheduling on high-complexity boundary dataset
# Critical validation: Can we resolve the -2.5% negative effect from Phase 2C?

experiment:
  name: "phase3b_cross_dataset_belgium"
  description: "Capacity-adaptive scheduling validation on Belgium-Netherlands high-complexity boundaries"
  phase: "phase3b"
  output_base: "phase3b"
  log_interval: 10
  seeds: [42, 123, 456, 789, 999, 2022, 3033, 4044, 5055, 6066]

device: "cpu"

# Test across architectures with capacity-adaptive scheduling
architectures:
  - name: "32x32"
    hidden_dims: [32, 32]  # ~1664 params, predicted optimal for medium complexity
  - name: "64x64" 
    hidden_dims: [64, 64]  # ~5888 params, predicted optimal for high complexity
  - name: "128x128"
    hidden_dims: [128, 128]  # Test scaling to larger architectures

model:
  type: "SpectralMLP"
  # hidden_dims set by architecture sweep

data:
  type: "BaarleMap"  # High boundary complexity from Phase 2C
  resolution: 200
  boundary_width: 3
  
training:
  epochs: 100
  learning_rate: 0.01
  optimizer: "adam"
  batch_size: null

regularization:
  type: "capacity_adaptive"
  beta: -0.2              # Use optimal β from Phase 3A
  sigma_base: 2.5
  final_sigma: 1.0
  strength: 0.1

baseline:
  type: "linear_schedule"   # Phase 2C baseline showing -2.5% negative effect  
  initial_sigma: 2.5
  final_sigma: 1.0
  strength: 0.1

metrics: ["accuracy", "loss", "criticality_score", "spectral_radius_avg", "capacity_ratio", "boundary_fractal_dim"]

# Phase 3B success criteria:
# - Eliminate negative effects: Belgium capacity-adaptive ≥ 0% vs baseline
# - Target success: Belgium capacity-adaptive ≥ +1% improvement
# - Validate capacity-complexity matching theory